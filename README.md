ğŸ§  Neural Network-Based NLP Classifier
======================================

ğŸš€ **Text Classification & Named Entity Recognition with RNNs, LSTMs, and Viterbi Algorithm**

This project implements **neural network-based text classification** and a **sequence labeling model using the Viterbi algorithm**. It trains models for **sentiment analysis** and **named entity recognition (NER)** using deep learning techniques such as **Recurrent Neural Networks (RNNs), Long Short-Term Memory (LSTMs), and the Viterbi algorithm**.

* * * * *

ğŸ¯ **Project Overview**
-----------------------

This NLP classifier is designed to:\
âœ… **Perform Sentiment Analysis** ğŸ“Š (Positive/Negative classification)\
âœ… **Recognize Named Entities (NER)** ğŸ” (Person, Location, Organization)\
âœ… **Compare RNNs & LSTMs for text classification**\
âœ… **Implement the Viterbi Algorithm for structured sequence prediction**

ğŸ“Œ The models are trained and tested on **IMDb movie reviews** (for sentiment analysis) and the **CoNLL 2003 NER dataset** (for named entity recognition).

* * * * *

ğŸ›  **Implemented Techniques**
-----------------------------

ğŸ”¹ **Text Classification** (Sentiment Analysis)

-   Uses RNNs and LSTMs
-   Compares accuracy of both models
-   Evaluates on IMDb movie reviews dataset

ğŸ”¹ **Named Entity Recognition (NER)**

-   Uses the **Viterbi Algorithm** for sequence labeling
-   Implements a structured prediction model

ğŸ”¹ **Optimization Techniques**

-   Word embedding
-   Dropout regularization
-   Adam optimizer

* * * * *

ğŸ“¥ **Dataset & Inputs**
-----------------------

The project uses two primary datasets:

ğŸ“Œ **IMDb Reviews Dataset** ğŸ­

-   Used for **sentiment classification**
-   Classifies reviews as **positive or negative**

ğŸ“Œ **CoNLL 2003 Named Entity Recognition Dataset** ğŸ·

-   Used for **NER**
-   Labels entities as **Person (PER), Location (LOC), Organization (ORG), or Other (O)**

### ğŸ”¢ **Input Format**

-   Text data for classification (movie reviews or entity-tagged sentences)
-   Word embeddings for deep learning models

### ğŸ“¤ **Output Format**

-   **For Sentiment Analysis:** Predicted sentiment (Positive/Negative)
-   **For NER:** Tagged words with entity labels

* * * * *

ğŸ“Š **Results & Performance**
----------------------------

### **Sentiment Analysis Results**

| Model | Training Accuracy | Test Accuracy |
| --- | --- | --- |
| RNN | 87.57% | 65.09% |
| LSTM | 99.93% | 84.08% |

ğŸ‘‰ **LSTMs outperform RNNs** significantly, particularly on longer sequences.

### **NER Results (Viterbi Algorithm)**

| Dataset | Precision | Recall | F1 Score |
| --- | --- | --- | --- |
| Dev | 52% | 45% | 48% |
| Test | 54% | 46% | 47% |

ğŸ‘‰ The **Viterbi Algorithm** achieves **48% F1-score** on the dev set, **47% on test**.

* * * * *

ğŸš€ **How to Run the Project**
-----------------------------

### ğŸ“¥ 1. **Clone the Repository**

`git clone https://github.com/your-repo/NLP-Classifier.git`  
`cd NLP-Classifier`

### ğŸ— 2. **Install Dependencies**

`pip install -r requirements.txt`

### â–¶ï¸ 3. **Train & Evaluate the Models**

#### **Train Sentiment Analysis Models**

`python main.py --task sentiment --model rnn  # Train RNN model`  
`python main.py --task sentiment --model lstm  # Train LSTM model`

#### **Train Named Entity Recognition (NER) Model**

`python main.py --task ner`

#### **Evaluate with Viterbi Algorithm**

`python conlleval.py ner.test output.txt`

* * * * *

ğŸ“¦ **Project Structure**
------------------------

- ğŸ“‚ **NLP-Classifier**  
- â”œâ”€â”€ ğŸ“„ `text_classification_rnn_lstm.py` *(Main script to train & evaluate text classification models using RNNs & LSTMs)*  
- â”œâ”€â”€ ğŸ“„ `viterbi_sequence_labeling.py` *(Implementation of the Viterbi algorithm for sequence labeling tasks, such as Named Entity Recognition (NER))*  
- â”œâ”€â”€ ğŸ“„ `conlleval.py` *(NER evaluation script for computing precision, recall, and F1-score based on CoNLL format output)*  
- â”œâ”€â”€ ğŸ“„ `model.simple` *(Pre-trained NER model used for inference and evaluation)*  
- â”œâ”€â”€ ğŸ“„ `ner.train` *(Training dataset for Named Entity Recognition (NER), containing labeled sequences of text)*  
- â”œâ”€â”€ ğŸ“„ `ner.dev` *(Development dataset for fine-tuning and hyperparameter selection in NER models)*  
- â”œâ”€â”€ ğŸ“„ `ner.test` *(Test dataset for final performance evaluation of the trained NER model)*  
- â”œâ”€â”€ ğŸ“„ `README.md` *(Comprehensive documentation of the project! ğŸš€)*  

* * * * *

ğŸ“Œ **Key Takeaways**
--------------------

âœ… **LSTMs outperform RNNs** for text classification\
âœ… **Viterbi Algorithm is crucial** for structured sequence prediction\
âœ… **Deep learning can extract sentiment & named entities** effectively

* * * * *

ğŸ”¥ **Future Enhancements**
--------------------------

ğŸ”¹ **Use Transformer-based models (BERT, GPT)** for improved accuracy\
ğŸ”¹ **Enhance Named Entity Recognition with CRF layer**\
ğŸ”¹ **Improve hyperparameter tuning for better results**

* * * * *

ğŸ“© **Contributing**
-------------------

Have suggestions? Found a bug? Open an issue or submit a pull request! ğŸš€

* * * * *

ğŸ† **Credits & References**
---------------------------

-   ğŸ“š **CoNLL 2003 Dataset** for Named Entity Recognition
-   ğŸ­ **IMDb Dataset** for Sentiment Analysis
-   ğŸ”— TensorFlow & Keras documentation

âœ¨ **A powerful NLP classifier using deep learning! ğŸš€**
